{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca2bd50",
   "metadata": {},
   "source": [
    "# Market Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651cc51",
   "metadata": {},
   "source": [
    "First let's load data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3861cba0",
   "metadata": {},
   "source": [
    "We want a function to score the features A-N in relation to Y1 and Y2, later, we'll also investigate relationships between features;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ff03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "X = train_data.drop([\"time\", \"Y1\", \"Y2\"], axis = 1)\n",
    "\n",
    "y = train_data[\"Y1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c9ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd641613",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"Y2\"]\n",
    "\n",
    "mi_scores = make_mi_scores(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d22647",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=100, figsize=(8, 5))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2820466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rels(features, target, nrows = 2, ncols = 7):\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, sharex=False, sharey=False, squeeze=False, figsize = [ncols * 5, nrows * 3 + 0.5])\n",
    "\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            axs[i,j].scatter(train_data[target], (train_data[features[i][j]].values), )\n",
    "            axs[i,j].set_title(f\"{features[i][j]} vs {target}\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "features = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"], [\"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\"]\n",
    "\n",
    "plot_rels(features, \"Y1\")\n",
    "\n",
    "plot_rels(features, \"Y2\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc5ebd9",
   "metadata": {},
   "source": [
    "Okay, we have some linear correlations in Y1, but Y2 is a lot more complicated, we want to run PCA to analyse underlying;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261cf053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "A = train_data.drop([\"time\", \"Y1\", \"Y2\"], axis=1)\n",
    "\n",
    "A_scaled = (A.values - np.mean(A.values)) / np.std(A.values) # Standardising before PCA\n",
    "\n",
    "pca = PCA(n_components= 3)\n",
    "\n",
    "A_pca = pca.fit_transform(A_scaled)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "A_pca[:,0] = -A_pca[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f0a1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 1, ncols = 3, figsize = [12, 4])\n",
    "\n",
    "ax1.scatter(A_pca[:,0], A_pca[:,1], c=train_data[\"Y2\"], cmap=\"viridis\")\n",
    "ax2.scatter(A_pca[:,0], A_pca[:,2], c=train_data[\"Y2\"], cmap=\"viridis\")\n",
    "ax3.scatter(A_pca[:,2], A_pca[:,1], c=train_data[\"Y2\"], cmap=\"viridis\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pd.DataFrame(A_pca, columns=[\"PC1\", \"PC2\", \"PC3\"])\n",
    "corrs = pcs.corrwith(train_data[\"Y2\"])\n",
    "print(corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = pcs[[\"PC1\" ,\"PC2\", \"PC3\"]]\n",
    "\n",
    "y = train_data[\"Y2\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "modelY2 = RandomForestRegressor(n_estimators=200)\n",
    "\n",
    "modelY2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelY2.predict(X_val)\n",
    "\n",
    "r2_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ffde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = train_data[[\"G\", \"M\", \"J\", \"C\", \"E\", \"H\", \"N\"]]\n",
    "\n",
    "y = train_data[\"Y1\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "modelY1 = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "modelY1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelY1.predict(X_val)\n",
    "\n",
    "r2_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c64da7",
   "metadata": {},
   "source": [
    "Let's create a Pipeline for applying this PCA shift and getting our prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "pipelineY2 = Pipeline([\n",
    "    (\"pca\", PCA(n_components = 3)),\n",
    "    (\"model\", RandomForestRegressor(n_estimators = 100))\n",
    "])\n",
    "\n",
    "X = train_data.drop([\"time\", \"Y1\", \"Y2\"], axis = 1)\n",
    "y = train_data[\"Y2\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "pipelineY2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipelineY2.predict(X_val)\n",
    "\n",
    "r2_score(y_pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3299b4",
   "metadata": {},
   "source": [
    "Okay... this is not ideal, but let's now have a look at autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295acd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def plot_pacfs(features, nrows = 2, ncols = 7):\n",
    "    fig, axs = plt.subplots(nrows = nrows, ncols = ncols, sharex=False, sharey=False, squeeze=False, figsize = [ncols * 5, nrows * 3 + 0.5])\n",
    "\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            plot_pacf(train_data[features[i][j]].values, axs[i,j], title = f\"{features[i][j]} Partial Autocorrelation\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "features = [[\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"], [\"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\"]]\n",
    "\n",
    "plot_pacfs(features)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacfs([[\"Y1\"],[\"Y2\"]], nrows = 2, ncols = 1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
